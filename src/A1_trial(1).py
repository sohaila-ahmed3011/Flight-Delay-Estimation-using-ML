# -*- coding: utf-8 -*-
"""A1_trial(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i9VTOs067JdNjf_XZtjTlMOvhFXIlLZQ

**Import Libraries**

---
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

"""**Loading and Exploring Dataset**

---


"""

flight_delay_df = pd.read_csv('flight_delay.csv')

# Process for calculating the flight duration
flight_delay_df.rename(columns = {'Scheduled depature time': 'Scheduled_departure_time', 'Scheduled arrival time': 'Scheduled_arrival_time'}, inplace = True)
flight_delay_df['Scheduled_departure_time'] = pd.to_datetime(flight_delay_df.Scheduled_departure_time)
flight_delay_df['Scheduled_arrival_time'] = pd.to_datetime(flight_delay_df.Scheduled_arrival_time)
# flight_duration = flight_delay_df.Scheduled_arrival_time - flight_delay_df.Scheduled_departure_time
flight_delay_df['flight_duration'] = (flight_delay_df['Scheduled_arrival_time'] - flight_delay_df['Scheduled_departure_time']).dt.total_seconds()/60

# Splitting the test and train data according to the scheduled departure time
train_data = flight_delay_df.loc[flight_delay_df.Scheduled_departure_time < '2018' , :]
test_data = flight_delay_df.loc[flight_delay_df.Scheduled_departure_time >= '2018', :]

x_train = train_data.reset_index()    # To remove any indices for the '2018' rows after splitting, since data is not organized sequentially
x_train = x_train.drop(['index','Delay','Scheduled_departure_time', 'Scheduled_arrival_time'], axis=1)   
y_train = train_data['Delay']

x_test = test_data.reset_index()
x_test = x_test.drop(['index','Delay','Scheduled_departure_time', 'Scheduled_arrival_time'], axis=1)
y_test = test_data['Delay']

print(x_train.head())
print(x_test.head())

print(flight_delay_df.columns)

print(flight_delay_df.isna().sum())

print(flight_delay_df.info)
print(flight_delay_df.dtypes)
print("Number categorical featues:", sum(flight_delay_df.dtypes =='object'))

"""**Data Statistics**

---


"""

print(x_train.describe())

"""**One-Hot Encoder**

---


"""

from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)
categ_feats = ['Depature Airport','Destination Airport']
encoder.fit(x_train[categ_feats])

def ohe_new_features(df, features_name, encoder):
    new_feats = encoder.transform(df[features_name])
    new_cols = pd.DataFrame(new_feats, dtype=int)
    new_df = pd.concat([df, new_cols], axis=1)
    new_df.drop(features_name, axis=1, inplace=True)
    return new_df

print('Before ohe encoding:')
print("x_train size before encoding", x_train.shape)
print("x_test size before encoding", x_test.shape)

x_train = ohe_new_features(x_train, categ_feats, encoder)
x_test = ohe_new_features(x_test, categ_feats, encoder)
print('\nAfter ohe encoding:')
print("x_train size after encoding", x_train.shape)
print("x_test size after encoding", x_test.shape)

"""**Null Values Calculation**

---


"""

# A function that checks for null cells
def count_nans(df):
    return df.isna().sum().sum()

# The number of empty cells both in x_train and x_test
print("# of empty cells in x_train=", count_nans(x_train))
print("# of empty cells in x_test=", count_nans(x_test))

"""**Features Scaling**"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
scaler.fit(x_train)
x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)

"""**Data Visualization**



---



"""

plt.scatter(x_train[:,0], y_train, marker='.', label='Delay')
plt.title('Flight Duratuion vs Delay')
plt.xlabel('Flight Duratuion (minutes)')
plt.ylabel('Delay in minutes')
plt.legend(loc='best')
plt.show()

from sklearn.decomposition import PCA

dim_reducer = PCA(n_components=2)
x_train_reduced = dim_reducer.fit_transform(x_train)

plt.scatter(x_train_reduced[:, 0], x_train_reduced[:, 1], marker='.')
plt.show()

"""**Outlier Detection & Removal**

---


"""

from sklearn.neighbors import LocalOutlierFactor

# selecting one predictor/feature from dataset (flight duration)
x_train_1f = x_train[:,0]
x_train_1f = x_train_1f.reshape(-1,1)

local_outlier_factor = LocalOutlierFactor()
y_pred = local_outlier_factor.fit_predict(x_train_1f)

# selecting all the rows that are not outliers
mask = y_pred != -1
x_train_1f, y_train = x_train_1f[mask, :], y_train[mask]

# summarize the shape of the updated training dataset
print(x_train_1f.shape, y_train.shape)

plt.scatter(x_train_1f[:,0], y_train, marker='.', label='Delay')
plt.title('Flight Duratuion vs Delay')
plt.xlabel('Flight Duratuion (minutes)')
plt.ylabel('Delay in minutes')
plt.legend(loc='best')
plt.show()

"""**Linear Regression Model**"""

from sklearn.linear_model import LinearRegression

# fit the model
regressor = LinearRegression()
regressor.fit(x_train_1f, y_train)
print(f"Model intercept : {regressor.intercept_}")
print(f"Model coefficient : {regressor.coef_}")

# evaluate the model
x_test_1f = x_test[:,0]
x_test_1f = x_test_1f.reshape(-1,1)
y_pred = regressor.predict(x_test_1f)
eval_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

print(x_test_1f.shape)

print(eval_df)

"""**Model evaluation using the appropriate evaluation metrics**

---


"""

from sklearn import metrics

# evaluate predictions
print('Test Error:')
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
print('Coefficient of Determination:', metrics.r2_score(y_test, y_pred))

"""**Polynomial Regression**

---


"""

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures    #to convert the original features into their higher order terms 
from sklearn.linear_model import LinearRegression
from sklearn import metrics
from sklearn.model_selection import cross_val_score


degrees = [2, 3, 4]

plt.figure(figsize=(14, 5))
for i in range(len(degrees)):
    ax = plt.subplot(1, len(degrees), i + 1)
    plt.setp(ax, xticks=(), yticks=())

    polynomial_features = PolynomialFeatures(degree=degrees[i])
    linear_regression = LinearRegression()
    pipeline = Pipeline([("polynomial_features", polynomial_features), ("linear_regression", linear_regression)])
    pipeline.fit(x_train_1f.flatten()[:, np.newaxis], y_train)
    y_pred_tr = pipeline.predict(x_train_1f)
    x_test_1f = x_test[:,0]
    x_test_1f = x_test_1f.reshape(-1,1)
    y_pred = pipeline.predict(x_test_1f)
    # Evaluate the models using crossvalidation
    scores = cross_val_score(pipeline, x_train_1f.flatten()[:, np.newaxis], y_train, scoring="neg_mean_squared_error", cv=10)

    print('\nDegree',degrees[i] )
    print('Train Error: ')
    print('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y_pred_tr))
    print('Mean Squared Error:', metrics.mean_squared_error(y_train, y_pred_tr))
    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred_tr)))
    print('Coefficient of Determination:', metrics.r2_score(y_train, y_pred_tr))
    print('\nTest Error: ')
    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
    print('Coefficient of Determination:', metrics.r2_score(y_test, y_pred))
    
    x_test_1f =np.linspace(x_train_1f.min(), x_train_1f.max(), 100)
    plt.plot(x_test_1f, pipeline.predict(x_test_1f[:, np.newaxis]), 'r', label="Model")
    plt.scatter(x_train_1f, y_train, edgecolor='b', s=20, label="Delay")
    plt.xlabel("flight duration")
    plt.ylabel("delay")
    plt.legend(loc="best")
    plt.title("Degree {}\nMSE = {:.2e}(+/- {:.2e})".format(degrees[i], -scores.mean(), scores.std()))

plt.show()

"""**Regularization using Lasso Regressor**

---


"""

from sklearn.linear_model import Lasso, Ridge
from sklearn.model_selection import train_test_split
from sklearn import metrics

#x_train_1f, x_val, y_train, y_val = train_test_split(x_train_1f, y_train, test_size=1/8, random_state=123)

alphas = [2.2, 2, 1.5, 1.3, 1.2, 1.1, 1, 0.3, 0.1]
losses = []
for alpha in alphas:
    lasso = Lasso(alpha=alpha)
    lasso.fit(x_train_1f, y_train)
    print("Lasso Coefficient", lasso.coef_)
    y_pred = lasso.predict(x_test)
    mse = mean_squared_error(y_test, y_pred)
    losses.append(mse)
plt.plot(alphas, losses)
plt.title("Lasso alpha value selection")
plt.xlabel("alpha")
plt.ylabel("Mean squared error")
plt.show()

best_alpha = alphas[np.argmin(losses)]
print("Best value of alpha:", best_alpha)



lasso = Lasso(best_alpha)
lasso.fit(x_train_1f, y_train)
x_test_1f = x_test[:,0]
x_test_1f = x_test_1f.reshape(-1,1)
y_pred = lasso.predict(x_test_1f)
print('Test Error:')
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
print('Coefficient of Determination:', metrics.r2_score(y_test, y_pred))

